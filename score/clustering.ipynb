{"cells":[{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(4, 6),\n"," (5, 7),\n"," (5, 24),\n"," (6, 137),\n"," (6, 156),\n"," (6, 306),\n"," (39, 53),\n"," (39, 114),\n"," (39, 189),\n"," (39, 307),\n"," (65, 69),\n"," (69, 163),\n"," (97, 98),\n"," (98, 99),\n"," (132, 134),\n"," (132, 269),\n"," (132, 274),\n"," (132, 345)]\n","[(5, 28),\n"," (5, 115),\n"," (6, 319),\n"," (32, 98),\n"," (34, 132),\n"," (39, 174),\n"," (39, 264),\n"," (39, 325),\n"," (69, 275),\n"," (69, 317),\n"," (98, 197),\n"," (132, 257)]\n"]}],"source":["import os\n","import csv\n","import pprint\n","\n","\n","sim = set()\n","not_sim = set()\n","\n","header = [5,39,6,69,98,132]\n","data = [\n","    [\n","        [7, 24],\n","        [28, 115]\n","    ],\n","    [\n","        [114, 189, 53, 307],\n","        [325, 174, 264]\n","    ],\n","    [\n","        [4, 156, 137, 306],\n","        [319]\n","    ],\n","    [\n","        [65, 163],\n","        [275, 317]\n","    ],\n","    [\n","        [97, 99],\n","        [32, 197]\n","    ],\n","    [\n","        [134, 269, 345, 274],\n","        [257, 34]\n","    ]\n","]\n","\n","for i,head in enumerate(header):\n","    for d in data[i][0]:\n","        sim.add(tuple(sorted([head, d])))\n","    for d in data[i][1]:\n","        not_sim.add(tuple(sorted([head, d])))\n","\n","sim = sorted(list(sim))\n","not_sim = sorted(list(not_sim))\n","pprint.pprint(sim)\n","pprint.pprint(not_sim)\n","\n","\n","save_path = f\"./data/note_sims\"\n","os.makedirs(save_path, exist_ok=True)\n","sim_save_file = f'{save_path}/sim.csv'\n","not_sim_save_file = f'{save_path}/not_sim.csv'\n","\n","with open(sim_save_file, 'w', newline='') as csvfile:\n","    fieldnames = [\"Source\", \"Target\"]\n","    writer = csv.writer(csvfile)\n","    writer.writerows(sim)\n","\n","with open(not_sim_save_file, 'w', newline='') as csvfile:\n","    fieldnames = [\"Source\", \"Target\"]\n","    writer = csv.writer(csvfile)\n","    writer.writerows(not_sim)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# データの読み込み"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1243,"status":"ok","timestamp":1686035871502,"user":{"displayName":"伊東晴紀","userId":"04309229566094297429"},"user_tz":-540},"id":"5twALTEgkLcP","outputId":"b9b3c91e-9007-4e88-bc6f-6fa30e30d0d3"},"outputs":[],"source":["import json\n","from pprint import pprint\n","import os\n","\n","feature_vector_file_name = \"_d_cnt_log_move_flip_fv.json\"\n","file_path = f\"{os.getcwd()}/data/{feature_vector_file_name}\"\n","\n","with open(file_path) as f:\n","  data = json.load(f)\n","\n","pprint(data[:5])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# クラスタリング"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":921,"status":"ok","timestamp":1686038482549,"user":{"displayName":"伊東晴紀","userId":"04309229566094297429"},"user_tz":-540},"id":"s0ObjrYSiQ4D","outputId":"b32a2fc8-fb7b-429a-aef3-fe487c9956a6"},"outputs":[],"source":["from sklearn.cluster import AffinityPropagation,MeanShift,DBSCAN,OPTICS,estimate_bandwidth\n","import numpy as np\n","\n","data = np.array(data)\n","\n","method = \"AffinityPropagation\"\n","method = \"MeanShift\"\n","method = \"DBSCAN\"\n","# method = \"OPTICS\"\n","\n","if method == \"AffinityPropagation\":\n","  # TODO: シルエットスコアで調節した結果を評価するといいらしいとChatGPTが言ってた\n","  # preference\n","  # -200は細かいかなって感じ\n","  # -400がまあって感じ\n","  # -800はやりすぎかなって感じ\n","  # damping\n","  clustering_result = AffinityPropagation(\n","      random_state=5,\n","      preference=-1,\n","      damping=0.9\n","    ).fit_predict(data)\n","elif method == \"MeanShift\":\n","  bw = estimate_bandwidth(data, quantile=0.05, n_samples=500)\n","  print(\"bw\",bw)\n","  clustering_result = MeanShift(\n","      bandwidth=bw\n","    ).fit_predict(data)\n","elif method == \"DBSCAN\":\n","  # init eps = 0.5, min samples=5\n","  import numpy as np\n","  from sklearn.neighbors import NearestNeighbors\n","  import matplotlib.pyplot as plt\n","\n","  def get_kdist_plot(X=None, k=None, radius_nbrs=1.0):\n","      nbrs = NearestNeighbors(n_neighbors=k, radius=radius_nbrs).fit(X)\n","\n","      # For each point, compute distances to its k-nearest neighbors\n","      distances, indices = nbrs.kneighbors(X) \n","\n","      distances = np.sort(distances, axis=0)\n","      distances = distances[:, k-1]\n","\n","      # Plot the sorted K-nearest neighbor distance for each point in the dataset\n","      plt.figure(figsize=(8,8))\n","      plt.plot(distances)\n","      plt.xlabel('Points/Objects in the dataset', fontsize=12)\n","      plt.ylabel('Sorted {}-nearest neighbor distance'.format(k), fontsize=12)\n","      plt.grid(True, linestyle=\"--\", color='black', alpha=0.4)\n","      plt.ylim((0,1))\n","      plt.show()\n","      plt.close()\n","\n","  k = 2 * len(data[0]) - 1 # k=2*{dim(dataset)} - 1\n","  get_kdist_plot(X=data, k=k)\n","  clustering_result = DBSCAN(eps=0.5, min_samples=3).fit_predict(data)\n","elif method == \"OPTICS\":\n","  clustering_result = OPTICS(\n","      min_samples=5,\n","      max_eps=np.inf,\n","      cluster_method=\"xi\",\n","      xi=0.5,\n","    ).fit_predict(data)\n","\n","clustering_result += 1\n","\n","print(\"dat shape; col:\", len(data),\" row:\", len(data[0]))\n","print(len(clustering_result))\n","print(clustering_result)\n","clustering_labels = set(clustering_result)\n","print(len(clustering_labels),clustering_labels)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 各次元削減による描画"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":8416,"status":"ok","timestamp":1686038495779,"user":{"displayName":"伊東晴紀","userId":"04309229566094297429"},"user_tz":-540},"id":"kap16adnm4F4","outputId":"13dfa255-ab23-4f11-ff60-2781967de917"},"outputs":[],"source":["from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","import os\n","import datetime\n","\n","save_dir_name = \"_vis-result\"\n","dir_path = f\"./data/{save_dir_name}/\"\n","time_dir_path = dir_path + f\"{str(datetime.date.today())}/\"\n","try:\n","    os.mkdir(dir_path)\n","except FileExistsError:\n","    pass\n","try:\n","    os.mkdir(time_dir_path)\n","except FileExistsError:\n","    pass\n","\n","data = np.array(data)\n","file_explain = f\"{datetime.datetime.now().time()}_clustering_{method}\"\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=2, random_state=0)\n","data_pca = pca.fit_transform(data)\n","\n","plt.scatter(data_pca[:,0],data_pca[:,1], c=clustering_result, cmap=\"gist_ncar\")\n","plt.savefig(time_dir_path + f\"{file_explain}_plot-pca.png\")\n","plt.show()\n","\n","tsne = TSNE(n_components=2, random_state=0)\n","data_tsne = tsne.fit_transform(data)\n","\n","plt.scatter(data_tsne[:,0],data_tsne[:,1], c=clustering_result, cmap=\"gist_ncar\")\n","plt.savefig(time_dir_path + f\"{file_explain}_plot-tsne.png\")\n","plt.show()\n","\n","from umap import UMAP\n","\n","umap = UMAP(n_components=2, random_state=0)\n","data_umap = umap.fit_transform(data)\n","pprint(data_umap)\n","\n","plt.scatter(data_umap[:,0],data_umap[:,1], c=clustering_result, cmap=\"gist_ncar\")\n","plt.savefig(time_dir_path + f\"{file_explain}_plot-umap.png\")\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 結果の確認"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","from pprint import pprint\n","from section_divide import get_section\n","\n","file_path = \"./data/_feature_vector.json\"\n","\n","\n","with open(file_path) as f:\n","  data = json.load(f)\n","data = np.array(data)\n","# cluster_labels = set(clustering_result)\n","\n","\n","# pprint(sections[1])\n","print(len(sections), len(clustering_result))\n","label_by_note_count:dict[int,set] = dict()\n","cnt_by_note_count:dict[int,int] = dict()\n","\n","note_count_by_label:dict[int,set] = dict()\n","\n","note4_sections =  list()\n","note4_sections_idx =  list()\n","\n","for i,section in enumerate(sections):\n","  \n","  if label_by_note_count.get(len(section)) is not None:\n","    label_by_note_count[len(section)].add(clustering_result[i])\n","    cnt_by_note_count[len(section)] += 1\n","  else:\n","    label_by_note_count[len(section)] = set()\n","    cnt_by_note_count[len(section)] = 0\n","  \n","  if note_count_by_label.get(clustering_result[i]) is not None:\n","    note_count_by_label[clustering_result[i]].add(len(section))\n","  else:\n","    note_count_by_label[clustering_result[i]] = set()\n","    \n","  if len(section) == 4:\n","    note4_sections.append(section)\n","    note4_sections_idx.append(i)\n","\n","print(\"=== ノーツ数が4である区間の数，ノーツ数が4である区間のラベルの数，そのラベル\")\n","print(cnt_by_note_count[4], len(label_by_note_count[4]), label_by_note_count[4])\n","print(\"=====\")\n","\n","# print(\"=== 「ノーツ数が4であるラベル」に属する区間が持つノーツ数\")\n","# for label in label_by_note_count[4]:\n","#   print(label,note_count_by_label[label])\n","# print(\"=====\")\n","\n","clustering_labels = set(clustering_result)\n","from collections import defaultdict\n","data_by_label = defaultdict(set)\n","for i in range(len(data)):\n","  data_by_label[clustering_result[i]].add(i)\n","\n","\n","notes_file_path = \"./data/m155_notes-test.json\"\n","sections = get_section(notes_file_path)\n","\n","ns = defaultdict(list)\n","for l in label_by_note_count[4]:\n","  ids = data_by_label[l]\n","  for i in ids:\n","    ns[len(sections[i])].append(i)\n","    # if len(sections[i]) == 4:\n","    #   n4.append(i)\n","\n","for k,v in ns.items():\n","  print(f\"note count = {k}\\tlength = {len(v)}\")\n","\n","# import matplotlib.pyplot as plt\n","\n","# # print(\"===\")\n","# for i,idx in enumerate(note4_sections_idx):\n","#   find = False\n","#   for j,jdx in enumerate(note4_sections_idx):\n","#     if clustering_result[idx] == clustering_result[jdx]:\n","#       continue\n","    \n","#     print(clustering_result[idx], clustering_result[jdx])\n","    \n","#     fig = plt.figure(figsize = (10,4), facecolor='lightblue')\n","#     ax1 = fig.add_subplot(1, 2, 1)\n","#     ax2 = fig.add_subplot(1, 2, 2)\n","\n","    \n","#     xs = [item[\"x\"] for item in note4_sections[i]]\n","#     ys = [item[\"y\"] for item in note4_sections[i]]\n","#     miny = min(ys)\n","#     ys = [y-miny for y in ys]\n","#     ax1.scatter(xs,ys, color=\"b\", label=clustering_result[note4_sections_idx[idx]])\n","#     ax1.set_xlim([-0.3,12.3])\n","#     # ax1.set_ylim(bottom=0)\n","    \n","#     xs = [item[\"x\"] for item in note4_sections[j]]\n","#     ys = [item[\"y\"] for item in note4_sections[j]]\n","#     miny = min(ys)\n","#     ys = [y-miny for y in ys]\n","#     ax2.scatter(xs,ys,color=\"r\", label=clustering_result[note4_sections_idx[jdx]])\n","#     ax2.set_xlim([-0.3,12.3])\n","\n","#     plt.show()\n","    \n","#     break\n","#   else:\n","#     continue\n","  \n","#   break\n","\n","\n","# pprint(note4_sections[0])\n","# print(\"&\")\n","# pprint(note4_sections[1])\n","# print(\"=====\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# クラスターごとのディレクトリに画像に出力"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clustering_labels = set(clustering_result)\n","# print(len(clustering_labels),clustering_labels)\n","\n","\n","import os\n","import datetime\n","\n","from section_divide import get_section\n","\n","\n","notes_file_path = \"./data/m155_notes-test.json\"\n","sections = get_section(notes_file_path)\n","\n","\n","base_dir = \"./data/_vis-result\"\n","time_dir_path = f\"{base_dir}/{str(datetime.date.today())}\"\n","cluster_labels_dir = f\"{time_dir_path}/{str(datetime.datetime.now().time())}-cluster-labels\"\n","\n","try:\n","    os.mkdir(base_dir)\n","except FileExistsError:\n","    pass\n","try:\n","    os.mkdir(time_dir_path)\n","except FileExistsError:\n","    pass\n","try:\n","    os.mkdir(cluster_labels_dir)\n","except FileExistsError:\n","    pass\n","\n","for label in clustering_labels:\n","    # ラベルが一致するデータのみをフィルタリング\n","    # plt.scatter(data_subset[:, 0], data_subset[:, 1], label=str(label))\n","    \n","    dir_path = f\"{cluster_labels_dir}/label-{label}/\"\n","    try:\n","        os.mkdir(dir_path)\n","    except FileExistsError:\n","        pass\n","    \n","    \n","    file_name = f\"{str(datetime.datetime.now().time())}\"\n","    print(file_name)\n","    \n","    data_range = clustering_result == label\n","    # print(data_range)\n","    data_subset = data[data_range]\n","    section_subset = [s for s,d in zip(sections,data_range) if d]\n","    \n","    for i,section in enumerate(section_subset):\n","        xs = [item[\"x\"] for item in section]\n","        ys = [item[\"y\"] for item in section]\n","        plt.scatter(xs,ys, color=\"b\", label=label)\n","        plt.xlim([-0.3,12.3])\n","        plt.savefig(f\"{dir_path}{i}_{file_name}.png\")\n","        plt.close()\n","\n","# plt.legend()\n","# plt.xlim(left=-5)\n","# plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOV5KFYzkgGbTUZ0xvPseAZ","mount_file_id":"1Tzrp2mPs5ksTADjmiQKnKKOMzNKud-fc","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
